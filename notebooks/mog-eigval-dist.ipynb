{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code for the toy experiment in the paper [The Numerics of GANs](https://arxiv.org/abs/1705.10461)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import sys, os\n",
    "from tqdm import tqdm as tqdm_notebook\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def kde(mu, tau, bbox=[-5, 5, -5, 5], save_file=\"\", xlabel=\"\", ylabel=\"\", cmap='Blues'):\n",
    "    values = np.vstack([mu, tau])\n",
    "    kernel = sp.stats.gaussian_kde(values)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis(bbox)\n",
    "    ax.set_aspect(abs(bbox[1]-bbox[0])/abs(bbox[3]-bbox[2]))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off') # labels along the bottom edge are off\n",
    "    plt.tick_params(\n",
    "        axis='y',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        right='off',         # ticks along the top edge are off\n",
    "        labelleft='off') # labels along the bottom edge are off\n",
    "    \n",
    "    xx, yy = np.mgrid[bbox[0]:bbox[1]:300j, bbox[2]:bbox[3]:300j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    f = np.reshape(kernel(positions).T, xx.shape)\n",
    "    cfset = ax.contourf(xx, yy, f, cmap=cmap)\n",
    "\n",
    "    if save_file != \"\":\n",
    "        plt.savefig(save_file, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def complex_scatter(points, bbox=None, save_file=\"\", xlabel=\"real part\", ylabel=\"imaginary part\", cmap='Blues'):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    if bbox is not None:\n",
    "        ax.axis(bbox)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    xx = [p.real for p in points]\n",
    "    yy = [p.imag for p in points]\n",
    "    \n",
    "    plt.plot(xx, yy, 'X')\n",
    "    plt.grid()\n",
    "\n",
    "    if save_file != \"\":\n",
    "        plt.savefig(save_file, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 1e-4\n",
    "reg_param = 10.\n",
    "batch_size = 512\n",
    "z_dim = 16\n",
    "sigma = 0.01\n",
    "method = 'conopt'\n",
    "divergence = 'standard'\n",
    "outdir = os.path.join('gifs', method)\n",
    "niter = 50000\n",
    "n_save = 500\n",
    "bbox = [-1.6, 1.6, -1.6, 1.6]\n",
    "do_eigen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "mus = np.vstack([np.cos(2*np.pi*k/8), np.sin(2*np.pi*k/8)] for k in range(batch_size))\n",
    "x_real = mus + sigma*tf.random_normal([batch_size, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "def generator_func(z):\n",
    "    net = slim.fully_connected(z, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    x = slim.fully_connected(net, 2, activation_fn=None)\n",
    "    return x\n",
    "        \n",
    "\n",
    "def discriminator_func(x):\n",
    "    # Network\n",
    "    net = slim.fully_connected(x, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    net = slim.fully_connected(net, 16)\n",
    "    logits = slim.fully_connected(net, 1, activation_fn=None)\n",
    "    out = tf.squeeze(logits, -1)\n",
    "\n",
    "    return out\n",
    "\n",
    "generator = tf.make_template('generator', generator_func)\n",
    "discriminator = tf.make_template('discriminator', discriminator_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = tf.random_normal([batch_size, z_dim])\n",
    "x_fake = generator(z)\n",
    "d_out_real = discriminator(x_real)\n",
    "d_out_fake = discriminator(x_fake)\n",
    "\n",
    "# Loss\n",
    "if divergence == 'standard':\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=d_out_real, labels=tf.ones_like(d_out_real)\n",
    "    ))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=d_out_fake, labels=tf.zeros_like(d_out_fake)\n",
    "    ))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=d_out_fake, labels=tf.ones_like(d_out_fake)\n",
    "    ))\n",
    "elif divergence == 'JS':\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=d_out_real, labels=tf.ones_like(d_out_real)\n",
    "    ))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=d_out_fake, labels=tf.zeros_like(d_out_fake)\n",
    "    ))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "    g_loss = -d_loss\n",
    "elif divergence == 'indicator':\n",
    "    d_loss = tf.reduce_mean(d_out_real - d_out_fake)\n",
    "    g_loss = -d_loss \n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g_vars =  tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "d_vars =  tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate, use_locking=True)\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate, use_locking=True)\n",
    "\n",
    "# Compute gradients\n",
    "d_grads = tf.gradients(d_loss, d_vars)\n",
    "g_grads = tf.gradients(g_loss, g_vars)\n",
    "# Merge variable and gradient lists\n",
    "variables = d_vars + g_vars\n",
    "grads = d_grads + g_grads\n",
    "\n",
    "    \n",
    "if method == 'simga':\n",
    "    apply_vec = list(zip(grads, variables))\n",
    "elif method == 'conopt':\n",
    "    # Reguliarizer\n",
    "    reg = 0.5 * sum(\n",
    "        tf.reduce_sum(tf.square(g)) for g in grads\n",
    "    )\n",
    "    # Jacobian times gradiant\n",
    "    Jgrads = tf.gradients(reg, variables)\n",
    "    \n",
    "    apply_vec = [\n",
    "         (g + reg_param * Jg, v)\n",
    "         for (g, Jg, v) in zip(grads, Jgrads, variables) if Jg is not None\n",
    "    ]\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "with tf.control_dependencies([g for (g, v) in apply_vec]):\n",
    "    train_op = optimizer.apply_gradients(apply_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing gradient 1\n",
      "Dimension 0/256\n",
      "Dimension 1/256\n",
      "Dimension 2/256\n",
      "Dimension 3/256\n",
      "Dimension 4/256\n",
      "Dimension 5/256\n",
      "Dimension 6/256\n",
      "Dimension 7/256\n",
      "Dimension 8/256\n",
      "Dimension 9/256\n",
      "Dimension 10/256\n",
      "Dimension 11/256\n",
      "Dimension 12/256\n",
      "Dimension 13/256\n",
      "Dimension 14/256\n",
      "Dimension 15/256\n",
      "Dimension 16/256\n",
      "Dimension 17/256\n",
      "Dimension 18/256\n",
      "Dimension 19/256\n",
      "Dimension 20/256\n",
      "Dimension 21/256\n",
      "Dimension 22/256\n",
      "Dimension 23/256\n",
      "Dimension 24/256\n",
      "Dimension 25/256\n",
      "Dimension 26/256\n",
      "Dimension 27/256\n",
      "Dimension 28/256\n",
      "Dimension 29/256\n",
      "Dimension 30/256\n",
      "Dimension 31/256\n",
      "Dimension 32/256\n",
      "Dimension 33/256\n",
      "Dimension 34/256\n",
      "Dimension 35/256\n",
      "Dimension 36/256\n",
      "Dimension 37/256\n",
      "Dimension 38/256\n",
      "Dimension 39/256\n",
      "Dimension 40/256\n",
      "Dimension 41/256\n",
      "Dimension 42/256\n",
      "Dimension 43/256\n",
      "Dimension 44/256\n",
      "Dimension 45/256\n",
      "Dimension 46/256\n",
      "Dimension 47/256\n",
      "Dimension 48/256\n",
      "Dimension 49/256\n",
      "Dimension 50/256\n",
      "Dimension 51/256\n",
      "Dimension 52/256\n",
      "Dimension 53/256\n",
      "Dimension 54/256\n",
      "Dimension 55/256\n",
      "Dimension 56/256\n",
      "Dimension 57/256\n",
      "Dimension 58/256\n",
      "Dimension 59/256\n",
      "Dimension 60/256\n",
      "Dimension 61/256\n",
      "Dimension 62/256\n",
      "Dimension 63/256\n",
      "Dimension 64/256\n",
      "Dimension 65/256\n",
      "Dimension 66/256\n",
      "Dimension 67/256\n",
      "Dimension 68/256\n",
      "Dimension 69/256\n",
      "Dimension 70/256\n",
      "Dimension 71/256\n",
      "Dimension 72/256\n",
      "Dimension 73/256\n",
      "Dimension 74/256\n",
      "Dimension 75/256\n",
      "Dimension 76/256\n",
      "Dimension 77/256\n",
      "Dimension 78/256\n",
      "Dimension 79/256\n",
      "Dimension 80/256\n",
      "Dimension 81/256\n",
      "Dimension 82/256\n",
      "Dimension 83/256\n",
      "Dimension 84/256\n",
      "Dimension 85/256\n",
      "Dimension 86/256\n",
      "Dimension 87/256\n",
      "Dimension 88/256\n",
      "Dimension 89/256\n",
      "Dimension 90/256\n",
      "Dimension 91/256\n",
      "Dimension 92/256\n",
      "Dimension 93/256\n",
      "Dimension 94/256\n",
      "Dimension 95/256\n",
      "Dimension 96/256\n",
      "Dimension 97/256\n",
      "Dimension 98/256\n",
      "Dimension 99/256\n",
      "Dimension 100/256\n",
      "Dimension 101/256\n",
      "Dimension 102/256\n",
      "Dimension 103/256\n",
      "Dimension 104/256\n",
      "Dimension 105/256\n",
      "Dimension 106/256\n",
      "Dimension 107/256\n",
      "Dimension 108/256\n",
      "Dimension 109/256\n",
      "Dimension 110/256\n",
      "Dimension 111/256\n",
      "Dimension 112/256\n",
      "Dimension 113/256\n",
      "Dimension 114/256\n",
      "Dimension 115/256\n",
      "Dimension 116/256\n",
      "Dimension 117/256\n",
      "Dimension 118/256\n",
      "Dimension 119/256\n",
      "Dimension 120/256\n",
      "Dimension 121/256\n",
      "Dimension 122/256\n",
      "Dimension 123/256\n",
      "Dimension 124/256\n",
      "Dimension 125/256\n",
      "Dimension 126/256\n",
      "Dimension 127/256\n",
      "Dimension 128/256\n",
      "Dimension 129/256\n",
      "Dimension 130/256\n",
      "Dimension 131/256\n",
      "Dimension 132/256\n",
      "Dimension 133/256\n",
      "Dimension 134/256\n",
      "Dimension 135/256\n",
      "Dimension 136/256\n",
      "Dimension 137/256\n",
      "Dimension 138/256\n",
      "Dimension 139/256\n",
      "Dimension 140/256\n",
      "Dimension 141/256\n",
      "Dimension 142/256\n",
      "Dimension 143/256\n",
      "Dimension 144/256\n",
      "Dimension 145/256\n",
      "Dimension 146/256\n",
      "Dimension 147/256\n",
      "Dimension 148/256\n",
      "Dimension 149/256\n",
      "Dimension 150/256\n",
      "Dimension 151/256\n",
      "Dimension 152/256\n",
      "Dimension 153/256\n",
      "Dimension 154/256\n",
      "Dimension 155/256\n",
      "Dimension 156/256\n",
      "Dimension 157/256\n",
      "Dimension 158/256\n",
      "Dimension 159/256\n",
      "Dimension 160/256\n",
      "Dimension 161/256\n",
      "Dimension 162/256\n",
      "Dimension 163/256\n",
      "Dimension 164/256\n",
      "Dimension 165/256\n",
      "Dimension 166/256\n",
      "Dimension 167/256\n",
      "Dimension 168/256\n",
      "Dimension 169/256\n",
      "Dimension 170/256\n",
      "Dimension 171/256\n",
      "Dimension 172/256\n",
      "Dimension 173/256\n",
      "Dimension 174/256\n",
      "Dimension 175/256\n",
      "Dimension 176/256\n",
      "Dimension 177/256\n",
      "Dimension 178/256\n",
      "Dimension 179/256\n",
      "Dimension 180/256\n",
      "Dimension 181/256\n",
      "Dimension 182/256\n",
      "Dimension 183/256\n",
      "Dimension 184/256\n",
      "Dimension 185/256\n",
      "Dimension 186/256\n",
      "Dimension 187/256\n",
      "Dimension 188/256\n",
      "Dimension 189/256\n",
      "Dimension 190/256\n",
      "Dimension 191/256\n",
      "Dimension 192/256\n",
      "Dimension 193/256\n",
      "Dimension 194/256\n",
      "Dimension 195/256\n",
      "Dimension 196/256\n",
      "Dimension 197/256\n",
      "Dimension 198/256\n",
      "Dimension 199/256\n",
      "Dimension 200/256\n",
      "Dimension 201/256\n",
      "Dimension 202/256\n",
      "Dimension 203/256\n",
      "Dimension 204/256\n",
      "Dimension 205/256\n",
      "Dimension 206/256\n",
      "Dimension 207/256\n",
      "Dimension 208/256\n",
      "Dimension 209/256\n",
      "Dimension 210/256\n",
      "Dimension 211/256\n",
      "Dimension 212/256\n",
      "Dimension 213/256\n",
      "Dimension 214/256\n",
      "Dimension 215/256\n",
      "Dimension 216/256\n",
      "Dimension 217/256\n",
      "Dimension 218/256\n",
      "Dimension 219/256\n",
      "Dimension 220/256\n",
      "Dimension 221/256\n",
      "Dimension 222/256\n",
      "Dimension 223/256\n",
      "Dimension 224/256\n",
      "Dimension 225/256\n",
      "Dimension 226/256\n",
      "Dimension 227/256\n",
      "Dimension 228/256\n",
      "Dimension 229/256\n",
      "Dimension 230/256\n",
      "Dimension 231/256\n",
      "Dimension 232/256\n",
      "Dimension 233/256\n",
      "Dimension 234/256\n",
      "Dimension 235/256\n",
      "Dimension 236/256\n",
      "Dimension 237/256\n",
      "Dimension 238/256\n",
      "Dimension 239/256\n",
      "Dimension 240/256\n",
      "Dimension 241/256\n",
      "Dimension 242/256\n",
      "Dimension 243/256\n",
      "Dimension 244/256\n",
      "Dimension 245/256\n",
      "Dimension 246/256\n",
      "Dimension 247/256\n",
      "Dimension 248/256\n",
      "Dimension 249/256\n",
      "Dimension 250/256\n",
      "Dimension 251/256\n",
      "Dimension 252/256\n",
      "Dimension 253/256\n",
      "Dimension 254/256\n",
      "Dimension 255/256\n",
      "Doing gradient 1\n",
      "Dimension 0/16\n",
      "Dimension 1/16\n",
      "Dimension 2/16\n",
      "Dimension 3/16\n",
      "Dimension 4/16\n",
      "Dimension 5/16\n",
      "Dimension 6/16\n",
      "Dimension 7/16\n",
      "Dimension 8/16\n",
      "Dimension 9/16\n",
      "Dimension 10/16\n",
      "Dimension 11/16\n",
      "Dimension 12/16\n",
      "Dimension 13/16\n",
      "Dimension 14/16\n",
      "Dimension 15/16\n",
      "Doing gradient 1\n",
      "Dimension 0/256\n",
      "Dimension 1/256\n",
      "Dimension 2/256\n",
      "Dimension 3/256\n",
      "Dimension 4/256\n"
     ]
    }
   ],
   "source": [
    "if do_eigen:\n",
    "    jacobian_rows = []\n",
    "    g_grads = tf.gradients(g_loss, g_vars)\n",
    "    g_grads = [-g for g in g_grads]\n",
    "    d_grads = tf.gradients(d_loss, d_vars)\n",
    "    d_grads = [-g for g in d_grads]\n",
    "    \n",
    "    for g_idx, g in enumerate(g_grads + d_grads):\n",
    "        print 'Doing gradient {}/{}'.format(g_idx, len(g_grads + d_grads))\n",
    "        g = tf.reshape(g, [-1])\n",
    "        len_g = int(g.get_shape()[0])\n",
    "        for i in range(len_g):\n",
    "            if i%10 == 0:\n",
    "                print '\\rDimension {}/{}'.format(i, len_g)\n",
    "            g_row = tf.gradients(g[i], g_vars)\n",
    "            d_row = tf.gradients(g[i], d_vars)\n",
    "        jacobian_rows.append(g_row + d_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice index 3 of dimension 0 out of bounds. for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [1], [1], [1], [1] and with computed input tensors: input[1] = <3>, input[2] = <4>, input[3] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c8385cc11126>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36m_SliceHelper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m   5428\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5429\u001b[0m         \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshrink_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5430\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   5431\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5432\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: slice index 3 of dimension 0 out of bounds. for 'strided_slice_1' (op: 'StridedSlice') with input shapes: [1], [1], [1], [1] and with computed input tensors: input[1] = <3>, input[2] = <4>, input[3] = <1>."
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "tf.gradients(g[i], g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_J(J_rows):\n",
    "    J_rows_linear = [np.concatenate([g.flatten() for g in row]) for row in J_rows]\n",
    "    J = np.array(J_rows_linear)\n",
    "    return J\n",
    "\n",
    "def process_J(J, save_file, bbox=None):\n",
    "    eig, eigv = np.linalg.eig(J)\n",
    "    eig_real = np.array([p.real for p in eig])\n",
    "    complex_scatter(eig, save_file=save_file, bbox=bbox)\n",
    "\n",
    "    \n",
    "def process_J_conopt(J, reg, save_file, bbox=None):\n",
    "    J2 = J - reg * np.dot(J.T, J)\n",
    "    eig, eigv = np.linalg.eig(J2)\n",
    "    eig_real = np.array([p.real for p in eig])\n",
    "    complex_scatter(eig, save_file=save_file, bbox=bbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Real distribution\n",
    "x_out = np.concatenate([sess.run(x_real) for i in range(5)], axis=0)\n",
    "kde(x_out[:, 0], x_out[:, 1], bbox=bbox, cmap='Reds', save_file='gt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "    \n",
    "eigrawdir = os.path.join(outdir, 'eigs_raw')\n",
    "if not os.path.exists(eigrawdir):\n",
    "    os.makedirs(eigrawdir)\n",
    "    \n",
    "eigdir = os.path.join(outdir, 'eigs')\n",
    "if not os.path.exists(eigdir):\n",
    "    os.makedirs(eigdir)\n",
    "\n",
    "        \n",
    "eigdir_conopt = os.path.join(outdir, 'eigs_conopt')\n",
    "if not os.path.exists(eigdir_conopt):\n",
    "    os.makedirs(eigdir_conopt)\n",
    "    \n",
    "ztest = [np.random.randn(batch_size, z_dim) for i in range(5)]\n",
    "progress  = tqdm_notebook(range(niter))\n",
    "\n",
    "if do_eigen:\n",
    "    J_rows = sess.run(jacobian_rows)\n",
    "    J = get_J(J_rows)\n",
    "\n",
    "for i in progress:\n",
    "    sess.run(train_op)\n",
    "    d_loss_out, g_loss_out = sess.run([d_loss, g_loss])\n",
    "    \n",
    "    if do_eigen and i % 500 == 0:\n",
    "        J[:, :] = 0.\n",
    "        for k in range(10):\n",
    "            J_rows = sess.run(jacobian_rows)\n",
    "            J += get_J(J_rows)/10.\n",
    "        with open(os.path.join(eigrawdir, 'J_%d.npz' % i), 'wb') as f:\n",
    "            np.save(f, J)\n",
    "\n",
    "    progress.set_description('d_loss = %.4f, g_loss =%.4f' % (d_loss_out, g_loss_out))\n",
    "    if i % n_save == 0:\n",
    "        x_out = np.concatenate([sess.run(x_fake, feed_dict={z: zt}) for zt in ztest], axis=0)\n",
    "        kde(x_out[:, 0], x_out[:, 1], bbox=bbox, save_file=os.path.join(outdir,'%d.png' % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "pattern = r'J_(?P<it>0).npz'\n",
    "\n",
    "bbox = [-3.5, 0.75, -1.2, 1.2]\n",
    "\n",
    "\n",
    "eigrawdir = os.path.join(outdir, 'eigs_raw')\n",
    "if not os.path.exists(eigrawdir):\n",
    "    os.makedirs(eigrawdir)\n",
    "    \n",
    "eigdir = os.path.join(outdir, 'eigs')\n",
    "if not os.path.exists(eigdir):\n",
    "    os.makedirs(eigdir)\n",
    "\n",
    "        \n",
    "eigdir_conopt = os.path.join(outdir, 'eigs_conopt')\n",
    "if not os.path.exists(eigdir_conopt):\n",
    "    os.makedirs(eigdir_conopt)\n",
    "    \n",
    "out_files = glob.glob(os.path.join(eigrawdir, '*.npz'))\n",
    "matches = [re.fullmatch(pattern, os.path.basename(s)) for s in out_files]\n",
    "matches = [m for m in matches if m is not None]\n",
    "\n",
    "for m in tqdm_notebook(matches):\n",
    "    it = int(m.group('it'))\n",
    "    J = np.load(os.path.join(eigrawdir, m.group()))\n",
    "    process_J(J, save_file=os.path.join(eigdir, '%d.png' % it), bbox=bbox)\n",
    "    process_J_conopt(J, reg=reg_param, save_file=os.path.join(eigdir_conopt, '%d.png' % it), bbox=bbox)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "widgets": {
   "state": {
    "0075f9ff3de144909cc50edc4c1cb337": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "01dba8657c5b412db7d8fb9b07141aa6": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "04325a4c28d34ebb992c6841c6969846": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0773cbe5777b470397607bee8e921c53": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0cd5e901ff164623861281556215187e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0f9ef0bc2c0547b291070768cc6f239e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "1bd14c90f59f49eda390cb0d0e6a6ba0": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "1eddde7d77f04f8e97b44f84cb4a2cbb": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "24b6ed4b45ee49c6a73a74d0395e14d9": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "26e386ab9a06478e8a4f13390ff95b4d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "2d09a2d00eb9470bb46fbe87a788b07a": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "346a910c499e41a8b01ca9d404e82b37": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3694b3815722475cb8d8ed226e45a51d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3854328516554f88ac7c8a364a44176e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "391a926685414f27bb1fe0746af1e734": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3aaebfee3e3f431b8631471d865890db": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3bdce2bc6d23453d90fee056b2e31a1c": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3bf6e6a3e98c45df9d715941612d24dc": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3eb2e8b48ff94e95b0b4604df64f0f20": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "3f53ab1c482641bcaa83c21dd93c0ca4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "4626e0fad24347ab88aeba589870a6f2": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "4717d907d8c742eabccc8fa4c0fd3746": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "4cfc10e014b648a6996ebe76fa96050d": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "574f9c09b9964d8ba642f16886762f6b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "62c9e6fe66ef4b899257d4ea245c1b01": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "675c51f20de64d22b703c497c88edb7f": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "6900c1a831fc4546a518d6ab755fd73a": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "6b77882aec574b30842c45b8ed8675c7": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "736a10343df1454baa976a219494b1d4": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "75c47e3e20b542bdb01b8810cadba0e8": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "76851bec2b944ebb86635930caa6d865": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "7781157d5cd94eaf8be01fc3b8276a6e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "77b4ef8e8b9a412b90fe547d11151a36": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "84387e91e6694aa3924d2069b891e18e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "85ed9e64f24840b9b6d945e4cb5fc613": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "8a51b5daac164d50abf58ffa5d85a696": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "8a7433612ecc4209b8203dba814146cf": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "8c982131efc04866ae10303be2f78b03": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "8cdee79dd4174027a0903c7ef54e1dbf": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "91cdc908966843b88f631110017b0e2f": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "925152cc6d86422dbc239efa4a4a0ff5": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9289616eb0ff4157a99e68c3fb42bfae": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "942031578d08453f94949483090f7119": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9574391b345045c783d1824def8f18a0": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "9617aee02f0a4f79855237d22baa361c": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a252fa6acd144050a3a44a9c9e84aca6": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a504c98d626c47abb62ce8bbc18a3442": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "a9e62617dd1346ebbde00aa71712d46a": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "ab2c63737d504a5a9af60dbf1adf568e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "ac6403c77f1e4ec7bc34138d9dd55792": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "af22496e6da64f64b74d8fb2ff9215bd": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "b72bf7ddfec64bfea97da504c8c7807b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "bffd98e11ea241f881c94651d9a4ed8a": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "cbc5c20caf4b49b3836a876bfbc0d856": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "cff50db4e21e4e8e9590d6c3614eb34e": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d0200250a3d5473d8b2fe18b9712d4ad": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d4e86dcdcbd1413b91d01b779aa533ba": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d6bde1c40c1b414abcdad39e79584167": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "d8ac5d648b00435aa104d4a11f07e1fa": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "de3b4389e3c1472b8eae3b5b05f054db": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "e895e9d33fd341f383131d29150a8bba": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "ecea692cdaab4195b5bafeae2574db50": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
